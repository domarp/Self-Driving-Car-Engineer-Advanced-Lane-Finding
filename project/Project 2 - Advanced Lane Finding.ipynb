{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "The objective of this project is to develop an algorithm to find lanes in images and videos taken from a vehicle camera. The algorithm in this project is expected to be of advanced complexity as compared to Project 1 and is expected to asccount for factors such as curving roads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach\n",
    "\n",
    "The following are the key steps in achieve lane detection:\n",
    "1. Camera calibration\n",
    "2. Remove distortion in images\n",
    "3. Leverage color transforms and image binarization techniques to find lane edges in the image\n",
    "4. Apply perspective transform\n",
    "5. Detect lane lines\n",
    "6. Determine radius of curvature of the road and distance from the center\n",
    "7. Warp the detected lane boundaries back onto the original image\n",
    "\n",
    "Since videos are a continuous set of images in the form of frames, the logic applied to detect lanes in video frames is modified to leverage the knowledge of lanes detected in the previous frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Structure\n",
    "There are two key folders for this project (the necessary README files have been placed in the respective folders):\n",
    "\n",
    "1. __project__ : This folder contains scripts related to this project\n",
    "\n",
    "    - image_utils.py : This module contains all the image utility functions such as image sharpening, camera calibration, undistortion, binary image creation, perspective transformations, filling polygons and creating final frames\n",
    "    - lane_utlis.py : This module contains all the lane utility functions such as finding the lane lines, fiting a polynomial function to the lane points, measuring the radius of curvature and distance from centre\n",
    "    - project2_advanced_lane_finding.ipynb : This is the main notebook which contains the pipeline definitions for image and video lane finding algorithms. A pipeline typically calls in various image and lane finding utility functions to detect lanes in images or videos\n",
    "    \n",
    "\n",
    "2. __output_images__ : This folder contains the images generated at various points in the lane detection pipelines.The outputs at different stages in the pipeline are saved for the image only files. For video inputs, only the final video is saved\n",
    "\n",
    "    - camera_cal : This folder contains the output of camera calibrated chessboard images\n",
    "    - undistorted_images : This folder contains the undistorted images of the 8 test images\n",
    "    - binary_images : This folder contains the binary images of the test images\n",
    "    - warped_images : This folder contains the perspective transformed binary test images (prefix binary_\\*), perspective transform of the undistorted non binary image with the perspective polygon (prefix warped_\\*) and undistorted image with the perspective polygon (inverse perspective transformed; prefic undistorted_\\*) of the test images\n",
    "    - warped_lanes : This folder contains the perspectie trasnformed bianry images with a polynomial line fit for the lanes along with the sliding windows that aid the lane detection\n",
    "    - final_frames : This folder contains the final output images with the detected lanes, radius of curvature and distance from center\n",
    "    - vidoes : This folder contains the vidoe outputs for the project videos\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lane detection pipeline\n",
    "The pipelines for image lane detection and video lane detection differ in the sense that the video lane detection pipeline leverages previously detected lane information (from previous video frames). Both the pipelines require as input camera calibration parameters to undistort the images / frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Camera Calibration__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camera calibration is perfromed using the provided chessboard images. Some sample uncalibrated - calibrated  combinations are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../camera_cal/calibration10.jpg\" alt=\"Uncalibrated\" style=\"width:40%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/camera_cal/calibration10_chessboard_corners.jpg\" alt=\"Calibrated\" style=\"width:40%\">\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../camera_cal/calibration2.jpg\" alt=\"Uncalibrated\" style=\"width:40%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/camera_cal/calibration2_chessboard_corners.jpg\" alt=\"Calibrated\" style=\"width:40%\">\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../camera_cal/calibration17.jpg\" alt=\"Uncalibrated\" style=\"width:40%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/camera_cal/calibration17_chessboard_corners.jpg\" alt=\"Calibrated\" style=\"width:40%\">\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lane detection pipeline steps\n",
    "The following function summarizes the lane detection for single images\n",
    "\n",
    "___NOTE : Please refer to the Jupyter notebook for details on all function arguments. The purpose of all code snippets in this document is to understand the flow of logic and not necessarily all the arguments___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_lane_finding_pipeline(image, write_file = False, file_name = None):\n",
    "    # 1. Undistortion\n",
    "    undistorted_image = image_undistortion(image, nx, ny, camera_calibration_params, write_file, file_name)\n",
    "    \n",
    "    # 1.a. Sharpen image\n",
    "    sharpened_image = image_sharpen(undistorted_image)\n",
    "    \n",
    "    # 2. Binary Image    \n",
    "    binary_image = create_binary_image(sharpened_image, mask_points, write_file, file_name)\n",
    "    \n",
    "    # 3. Perspective transform    \n",
    "    warpped_image_binary = create_or_inverse_perspective(binary_image, source_points, destination_points, False, True, \"binary_\" + file_name.split('/')[-1])\n",
    "    warpped_image = create_or_inverse_perspective(undistorted_image, source_points, destination_points)\n",
    "    undistorted_image_polygon = draw_polygon(undistorted_image, source_points, \n",
    "                                             True, \"undistorted_\" + file_name.split('/')[-1]) \n",
    "    warpped_image_polygon = draw_polygon(warpped_image, destination_points, \n",
    "                                         True, \"warped_\" + file_name.split('/')[-1])\n",
    "    \n",
    "    # 4. Fit polynomial    \n",
    "    image_lanes, image_lanes_plotted, ploty, left_fit, \\\n",
    "    right_fit, leftx_base, rightx_base = fit_polynomial(warpped_image_binary, write_file=write_file, \n",
    "                                                                                  write_file_name=file_name)\n",
    "    \n",
    "    # 5. Compute radii and distance to center\n",
    "    imshape = binary_image.shape\n",
    "    radii = measure_curvature_real(ploty,ym_per_pix,xm_per_pix, left_fit, right_fit)\n",
    "    dist_to_center = measure_distance_to_center(imshape, ploty, ym_per_pix, xm_per_pix, left_fit, right_fit)\n",
    "    \n",
    "    # 6.a. Inverse perspective\n",
    "    unwarped_image = fill_poly(undistorted_image, warpped_image_binary, ploty, left_fit, right_fit, \n",
    "                               source_points, destination_points)\n",
    "    \n",
    "    # 6.b. Add radii and distance and save file\n",
    "    final_frame = create_final_frame(unwarped_image, radii, dist_to_center, True, file_name)\n",
    "    \n",
    "    results = final_frame.copy()\n",
    "    return results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case the input to the pipeline are frames from a video file, the pipeline looks like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_lane_finding_pipeline(image, leftx_base=None, rightx_base=None, ploty = None,\n",
    "                                left_fit = None, right_fit = None,\n",
    "                                write_file = False, file_name = None):\n",
    "    # 1. Undistortion\n",
    "    undistorted_image = image_undistortion(image, nx, ny, camera_calibration_params)\n",
    "    \n",
    "    # 1.a. Sharpen image\n",
    "    sharpened_image = image_sharpen(undistorted_image)\n",
    "    \n",
    "    # 1.b. Smooth image\n",
    "    smooth_image = cv2.GaussianBlur(sharpened_image, (5, 5), 1.0)\n",
    "    \n",
    "    # 2. Binary Image    \n",
    "    binary_image = create_binary_image(smooth_image, mask_points, write_file, file_name)\n",
    "    \n",
    "    # 3. Perspective transform    \n",
    "    wrapped_image_binary = create_or_inverse_perspective(binary_image, source_points, destination_points)\n",
    "    wrapped_image = create_or_inverse_perspective(undistorted_image, source_points, destination_points)\n",
    "    undistorted_image_polygon = draw_polygon(undistorted_image, source_points) \n",
    "    wrapped_image_polygon = draw_polygon(wrapped_image, destination_points)\n",
    "    \n",
    "    # 4. Fit polynomial\n",
    "    try:\n",
    "        image_lanes, image_lanes_plotted, ploty, left_fit, right_fit, \\\n",
    "    leftx_base, rightx_base = fit_polynomial(wrapped_image_binary, leftx_base, rightx_base, ploty, left_fit, right_fit)\n",
    "    except:\n",
    "        return undistorted_image\n",
    "    \n",
    "    # 5. Compute radii and distance to center\n",
    "    imshape = binary_image.shape\n",
    "    radii = measure_curvature_real(ploty,ym_per_pix,xm_per_pix, left_fit, right_fit)\n",
    "    dist_to_center = measure_distance_to_center(imshape, ploty, ym_per_pix, xm_per_pix, left_fit, right_fit)\n",
    "    \n",
    "    # 6.a. Inverse perspective\n",
    "    unwarped_image = fill_poly(undistorted_image, wrapped_image_binary, ploty, left_fit, right_fit, \n",
    "                               source_points, destination_points)\n",
    "    \n",
    "    # 6.b. Add radii and distance and save file\n",
    "    final_frame = create_final_frame(unwarped_image, radii, dist_to_center)\n",
    "    \n",
    "    results = final_frame.copy()\n",
    "    return (results, leftx_base, rightx_base, ploty, left_fit, right_fit)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from some differences in the preprocessing steps in Step 1, the key differece is in Step 4 and this difference will be explained below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 1 : Undistortion and preprocessing__\n",
    "\n",
    "This step primarily involves undistorting the image based on the camera calibration parameter. The distorted and undistorted versions of the test images look as below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../test_images/straight_lines1.jpg\" alt=\"distorteds1\" style=\"width:40%; height:40%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/undistorted_images/straight_lines1_undistorted.jpg\" alt=\"undistorteds1\" style=\"width:40%\">\n",
    "  </div>\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../test_images/straight_lines2.jpg\" alt=\"distorteds2\" style=\"width:40%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/undistorted_images/straight_lines2_undistorted.jpg\" alt=\"undistorteds1\" style=\"width:40%\">\n",
    "  </div>\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../test_images/test1.jpg\" alt=\"distorted1\" style=\"width:40%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/undistorted_images/test1_undistorted.jpg\" alt=\"undistorted1\" style=\"width:40%\">\n",
    "  </div>\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../test_images/test2.jpg\" alt=\"distorted1\" style=\"width:40%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/undistorted_images/test2_undistorted.jpg\" alt=\"undistorted1\" style=\"width:40%\">\n",
    "  </div>\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../test_images/test3.jpg\" alt=\"distorted1\" style=\"width:40%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/undistorted_images/test3_undistorted.jpg\" alt=\"undistorted1\" style=\"width:40%\">\n",
    "  </div>\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../test_images/test4.jpg\" alt=\"distorted1\" style=\"width:40%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/undistorted_images/test4_undistorted.jpg\" alt=\"undistorted1\" style=\"width:40%\">\n",
    "  </div>\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../test_images/test5.jpg\" alt=\"distorted1\" style=\"width:40%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/undistorted_images/test5_undistorted.jpg\" alt=\"undistorted1\" style=\"width:40%\">\n",
    "  </div>\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../test_images/test6.jpg\" alt=\"distorted1\" style=\"width:40%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/undistorted_images/test6_undistorted.jpg\" alt=\"undistorted1\" style=\"width:40%\">\n",
    "  </div>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undistortion is followed by some basic processing of images like image sharpening or smoothing - this is dependant on the pipeline and have been found by experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2 : Create binary image__\n",
    "\n",
    "The snippet below summarizes the creation of the binary image. After experimentation, the S and L layers of the image were chosen for application of Sobel filter in the x direction with appropriate thresholds. Other layers experimented were layers in the YCrCb, LAB, LUV, RGB, grayscale color transforms. Sobel y and magnitude / direction were also experimented but not with better results.\n",
    "\n",
    "The output is the binary image with edges highlighted over a masked area in the image. The masked area corresponds to the region in which the lane is expected to be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls = cv2.cvtColor(undistorted_image, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "s_channel = hls[:,:,2]\n",
    "sobelx = cv2.Sobel(s_channel, cv2.CV_64F, 1, 0, ksize = 5)\n",
    "abs_sobelx = np.absolute(sobelx) \n",
    "scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "sxbinary = np.zeros_like(scaled_sobel)\n",
    "sxbinary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "    \n",
    "l_channel = hls[:,:,1]\n",
    "sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0, ksize = 5)\n",
    "abs_sobelx = np.absolute(sobelx) \n",
    "scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "lxbinary = np.zeros_like(scaled_sobel)\n",
    "lxbinary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1    \n",
    "    \n",
    "combined_binary = np.zeros_like(s_channel)\n",
    "combined_binary[((sxbinary==1) | (lxbinary==1))] = 1\n",
    "mask = np.zeros_like(s_channel)\n",
    "cv2.fillPoly(mask, np.int_([mask_points]), 1) #mask_points define the edges of the mask for region of interest\n",
    "combined_binary_mask = np.bitwise_and(combined_binary, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binary outputs of the undistorted images look as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/undistorted_images/straight_lines1_undistorted.jpg\" alt=\"distorteds1\" style=\"width:40%; height:40%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/binary_images/straight_lines1_binary.jpg\" alt=\"undistorteds1\" style=\"width:40%\">\n",
    "  </div>\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/undistorted_images/straight_lines2_undistorted.jpg\" alt=\"distorteds2\" style=\"width:40%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/binary_images/straight_lines2_binary.jpg\" alt=\"undistorteds1\" style=\"width:40%\">\n",
    "  </div>\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/undistorted_images/test1_undistorted.jpg\" alt=\"distorted1\" style=\"width:40%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/binary_images/test1_binary.jpg\" alt=\"undistorted1\" style=\"width:40%\">\n",
    "  </div>\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/undistorted_images/test2_undistorted.jpg\" style=\"width:40%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/binary_images/test2_binary.jpg\" alt=\"undistorted1\" style=\"width:40%\">\n",
    "  </div>\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/undistorted_images/test3_undistorted.jpg\" alt=\"distorted1\" style=\"width:40%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/binary_images/test3_binary.jpg\" alt=\"undistorted1\" style=\"width:40%\">\n",
    "  </div>\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/undistorted_images/test4_undistorted.jpg\" alt=\"distorted1\" style=\"width:40%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/binary_images/test4_binary.jpg\" alt=\"undistorted1\" style=\"width:40%\">\n",
    "  </div>\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/undistorted_images/test5_undistorted.jpg\" alt=\"distorted1\" style=\"width:40%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/binary_images/test5_binary.jpg\" alt=\"undistorted1\" style=\"width:40%\">\n",
    "  </div>\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/undistorted_images/test6_undistorted.jpg\" alt=\"distorted1\" style=\"width:40%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/binary_images/test6_binary.jpg\" alt=\"undistorted1\" style=\"width:40%\">\n",
    "  </div>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 3 : Perspective transform__\n",
    "\n",
    "The binary image is warped into a bird's eye view by perspective trasnform. The source and destination points to define the perspective were defined by experimentation.\n",
    "\n",
    "The following array of images display the images in the following order: <br>\n",
    "_Undistorted image with perspective polygon -> Perspective polygon on warped image -> Binary version of the warped image_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/undistorted_straight_lines1_polygon.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/warped_straight_lines1_polygon.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:0.5%;padding-left:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/binary_straight_lines1_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/undistorted_straight_lines2_polygon.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/warped_straight_lines2_polygon.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:0.5%;padding-left:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/binary_straight_lines2_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/undistorted_test1_polygon.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/warped_test1_polygon.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:0.5%;padding-left:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/binary_test1_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/undistorted_test2_polygon.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/warped_test2_polygon.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:0.5%;padding-left:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/binary_test2_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/undistorted_test3_polygon.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/warped_test3_polygon.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:0.5%;padding-left:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/binary_test3_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/undistorted_test4_polygon.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/warped_test4_polygon.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:0.5%;padding-left:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/binary_test4_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/undistorted_test5_polygon.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/warped_test5_polygon.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:0.5%;padding-left:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/binary_test5_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/undistorted_test6_polygon.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/warped_test6_polygon.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:0.5%;padding-left:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/binary_test6_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 4 : Fit Polynomial__\n",
    "\n",
    "_Fit polynomial for lane in an image_\n",
    "\n",
    "The __fit_polynomial()__ function in the lane utilities is used for this purpose. This function takes as input the warped binary image and applies the sliding window technique to detect the lane points. Once the lane points are detected, polynomial function is fit to these points to define the lane curve equation.\n",
    "\n",
    "_Modification for image that is a frame in a video_\n",
    "\n",
    "In case the image is a frame in a video, the pipeline preserves the polynomial fit from the the previous frame and passes it onto the __fit_polynomial()__ function. This function then leverages this knowledge to compare the polynomial fit obtained from the current image; in case the fit is not defined or defined on the basis of __points less than a threshold value__, the previous polynomial is continued in the current image as well. The threshold is preserved by the __min_pix_replot__ variable. The following code snippet exhibits the logic to obtain this comparison,  the __find_lane_pixels()__ function is the function that deploys the sliding window technique to identify the lane pixels. Apart from the polynomial fit, the __fit_polynomial()__ function also preserves the starting points of the previously detected lanes to be used by the sliding window algorithm as explained in the next note.\n",
    "\n",
    "_Note on sliding windows_\n",
    "\n",
    "- The starting point for the left lane sliding windows and the right lane sliding windows is determined by the pixel density (determined by the histogram of the lower half of the image) across the x axis OR as passed on from the previous frame of the video. \n",
    "- Once pixels are detected in a window the position of the new window is determined by the median x-values of the locations of the detected pixel. The median is chosen to account for outliers that might influence the standard mean computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_pix_replot = 8000\n",
    "leftx, lefty, rightx, righty, out_img, leftx_base, rightx_base = find_lane_pixels(binary_warped, leftx_base, rightx_base)\n",
    "\n",
    "# At this point left_fit holds the previous image polynomial, leftx holds the newly detected left lane pixels. \n",
    "# Similar for the right lane\n",
    "if ((left_fit==None) | (leftx.shape[0] > min_pix_replot)):\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "else:\n",
    "    pass\n",
    "if ((right_fit==None)| (rightx.shape[0] > min_pix_replot)):\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following array of images display the images in the following order:<br>\n",
    "_Perspective polygon on warped image -> Binary version of the warped image -> Lane fitted binary perspective with sliding windows_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/warped_straight_lines1_polygon.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/binary_straight_lines1_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:0.5%;padding-right:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_lanes/straight_lines1_warped.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/warped_straight_lines2_polygon.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/binary_straight_lines2_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:0.5%;padding-right:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_lanes/straight_lines2_warped.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/warped_test1_polygon.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/binary_test1_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:0.5%;padding-right:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_lanes/test1_warped.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/warped_test2_polygon.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/binary_test2_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:0.5%;padding-right:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_lanes/test2_warped.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/warped_test3_polygon.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/binary_test3_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:0.5%;padding-right:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_lanes/test3_warped.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/warped_test4_polygon.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/binary_test4_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:0.5%;padding-right:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_lanes/test4_warped.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/warped_test5_polygon.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/binary_test5_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:0.5%;padding-right:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_lanes/test5_warped.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/warped_test6_polygon.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_images/binary_test6_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:0.5%;padding-right:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_lanes/test6_warped.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 5 : Metric computations__\n",
    "\n",
    "The following two metrics are computed as explained by the code snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Radii of curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature_real(ploty, ym_per_pix, xm_per_pix, left_fit, right_fit):\n",
    "    \"\"\" Calculates the curvature of polynomial functions in meters \"\"\"\n",
    "    y_eval = np.max(ploty)\n",
    "    left_curverad = ((1 + (2*left_fit[0]*y_eval*ym_per_pix + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    right_curverad = ((1 + (2*right_fit[0]*y_eval*ym_per_pix + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0]) \n",
    "    \n",
    "    return (left_curverad+ right_curverad)//2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Distance of lane center to camera center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_distance_to_center(imshape, ploty, ym_per_pix, xm_per_pix, left_fit, right_fit):\n",
    "    \"\"\" Calculates the distance of camera center to lane center in meters \"\"\"\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    left = np.polyval(left_fit, y_eval)\n",
    "    right = np.polyval(right_fit, y_eval)\n",
    "    center = imshape[1]/2\n",
    "    dist_to_center = (center - (left + right)/2)*xm_per_pix\n",
    "    return dist_to_center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 6 : Inverse perspective transformation and unwarping of image__\n",
    "\n",
    "The final step is to perform inverse persepective transform on the binary perspective image with lanes detected to obtain the image with the area between the lanes highlighted and display radius of curvature and distance of center of lanes to camera center.\n",
    "\n",
    "The following array of images display the images in the following order:<br>\n",
    "_Original Image -> Lane fitted binary perspective with sliding windows -> Final output image_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../test_images/straight_lines1.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_lanes/straight_lines1_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:0.5%;padding-right:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/final_frames/straight_lines1_final.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../test_images/straight_lines2.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_lanes/straight_lines2_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:0.5%;padding-right:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/final_frames/straight_lines2_final.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../test_images/test1.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_lanes/test1_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:0.5%;padding-right:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/final_frames/test1_final.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../test_images/test2.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_lanes/test2_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:0.5%;padding-right:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/final_frames/test2_final.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../test_images/test3.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_lanes/test3_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:0.5%;padding-right:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/final_frames/test3_final.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../test_images/test4.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_lanes/test4_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:0.5%;padding-right:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/final_frames/test4_final.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../test_images/test5.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_lanes/test5_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:0.5%;padding-right:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/final_frames/test5_final.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../test_images/test6.jpg\" alt=\"undistorteds1\" style=\"width:30%;padding-right:1%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/warped_lanes/test6_warped.jpg\" alt=\"s1\" style=\"width:30%;padding-left:0.5%;padding-right:0.5%\" align=\"left\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img src=\"../output_images/final_frames/test6_final.jpg\" alt=\"distorteds1\" style=\"width:30%;padding-left:1%\" align=\"left\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video lane detection\n",
    "\n",
    "The approach explained above works well with the project video (see : /output_images/videos/output_project_video.mp4). However it does not quite work well with the challenge videos. \n",
    "- With the challenge_video.mp4, one of the issue is that of a parallel shade occuring at the seeming point of convergence between the two lanes. The effect of this is seen right from the beginning as the detected region on the left take a left curve rather than a right one. Investigating the binary perspective transformed image of this frame reveals that the top portion of the left lane included edges detected from the road edge (inside the shade). This can potentially be removed by better image pre processing techniques to detect only the lane edges and remove the other edges. \n",
    "- For the harder_challenge_video.mp4, the issue is shades and changing elevations combined with curves - all happening almost at the same locations. We need better algorithms to account for such changes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
